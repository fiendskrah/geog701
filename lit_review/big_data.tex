In 1997, Michael Batty defined 3 distinct aspects of the digital world
for geographers to investigate: \emph{cspace} (the space within computers),
\emph{cyberspace} (the use of computers to communicate), and \emph{cyberplace} (the
infrastructures of the digital world). These aspects are
interconnected and constantly influencing each
other \citep{batty1997VirtualGeography}. While the intervening 25
years have been unprecedented in technological development, Batty's
articulation of virtual geography as expressions of the digitized in
the physical world remains relevant for the current work. Here, we are
concerned with physical manifestations of the digital infrastructures
in urban systems and public policy.

This section will explore these manifestations across disparate policy
areas. In order to loosely group these areas, we examine them through
the lens of `computationalism': the belief that computers and
algorithms \emph{can and must} underwrite the fundamental organization
of society and the distribution of resources. This ideological belief
is fundamental in city councils and municipal administrators who have
experienced political pressures to do more with less - the directive
to be more efficient naturally leads administrators to turn to
computers to help them perform their duties. In his book \emph{The
Cultural Logic of Computation}, David Golumbia positions
computationalism within the larger tradition of rational individualism
and global neoliberal hegemony, all of which greatly influence the
culture and pathway of municipal policy making in the United
States \citep{golumbia2009CulturalLogic}. Unfortunately, as we explore
below, algorithmic logics do not mitigate the systemic issues like
racism as true computationalists would argue, instead they reflect
(and in some cases, amplify) the biases of their authors.

\subsection{Computationalism in Policing}
With computationalism in mind, we return now to the topic of
policing. Police departments have historically been on the cutting
edge of trying to incorporate new technologies into official police
duties. To the computationalist, this is unequivocally a good
practice, as the imputation of computational logics have the potential
to remove the deeply consequential biases of individual offers.

However, \cite{richardson2019DirtyData} demonstrates that in the
application of predictive policing systems, this is simply not the
case. The authors investigate three police departments that are under
consent decrees or other federal investigations for racist or corrupt
practices that are simultaneously developing predictive policing
systems, which, unsurprisingly, are found to reproduce the biases of
the creators. This dynamic is the result of police data which reflect
the decisions and priorities of the department, including focuses on
certain kinds of crime (violent, street, property, and quality of
life) over others (white-collar). Despite any studies that show a
significantly higher occurrence of white-collar crime over property or
violent crime (as cited in \cite{richardson2019DirtyData}), police
databases are primarily focused on the latter while largely avoiding
the former. This reflects the computational nature of municipal
policing policies - rather than addressing the crimes that are
impacting far more people, the police are guided to manage the
aesthetics of the city by devoting all resources to addressing the
more salient crimes and organizing the homeless away from developing
centers of commerce - avoiding altogether the prospect of diverting
funds from runaway police budgets towards programs that address the
causes of crime.

The predictive policing systems described here are both ineffective at
their stated goals and premised on the corruption that precede
them. The fact that police departments are developing systems for
predictive policing while under federal investigations for corruption
and abuse speaks to the general autonomy that police departments have,
but the lack of oversight (or even a general understanding) associated
with big data practices is another theme that we will find recurring
throughout this section.

\subsection{On the Ubiquity of 'Big Data'}
Big Data is a catch-all phrase that has colloquially come to mean the
use of massive datasets to guide our decisions and policies. However,
The implications of Big Data is widespread and immense, in some ways
more theoretical than quantifiable. Jeremy Crampton defines Big Data
as ``a matter of technologic practices, epistemologies, and
ontologies.'' This definition captures the essence of Big Data as
a \emph{practice} rather than simply large and complex datasets. Big
Data centers the uninhibited, wanton harvesting of data - pieces of
information about humans, essentializing and generalizing
them. \cite{crampton2015CollectIt} provides an accounting of the facts
about the intelligence community revealed by Edward Snowden, including
characteristics about the overarching intelligence
apparatus/workforce, which contains the enrollment of academia, social
media, and the private sector. In addition to both the still-secret and
publicly known uses of `activity based intelligence' disclosed by
Snowden, these practices have become widely accepted across the digital
dimensions of our lives, largely due to the computational logics
of capitalism that guide the public and private sectors to prioritize
short-term economic gains over promoting equitable societies and
sustainable practices.

Lest we descend into cynicism in the upcoming sections, we should
briefly acknowledge that there are practical applications for new
technologies that can improve quality of life through pleasure and
convenience that don't necessarily comport with the computational
logics of capitalism. In the United States, the speed at which digital
platforms are put to market by way of investors (and indeed, the
preeminent privatization of all life) somewhat precludes this
conceptualization, but \cite{certoma2020DigitalSocial} elaborates a
research agenda for digital social innovations (DSI) in a European
context, which refer to initiatives that leverage digital technologies
to co-create solutions for a wide range of social needs. They cite a
few examples: The reusing of abandoned buildings, and the organization
of new commons. Of particular interest here is the use of DSI in
creating local sharing economies in neighborhoods. The recency of
digital platforms in the sharing economy, the aftermarket economy,
local civic communication, and micrologistics make it possible to
imagine the use of digital platforms absent extractive practices, but
work will need to be done to reclaim these spaces from exploitation.

\subsection{California Proposition 22 (2020)}
The context surrounding and passage of California proposition 22 in
2020, detailed in \cite{cherry2021DispatchUnited}, is relevant
here. Prop 22 was propelled by Uber, Lyft, Doordash, and other
ridesharing/micrologistics companies in response to California AB5
(2019), which codified gig workers as employees under California
law. This change in categorization would have required the companies
to provide their workers with additional benefits and rights
(including collective bargaining). Prop 22 passed by a margin of 2.5
million votes, largely as a result of the companies breaking records
for money spent on advertising, much of which went above and beyond
the typical bad-faith arguments used to convey and posit arguments
about complicated labor law to an overstimulated and
attention-depleted voting population - there were instances of food
delivery workers being asked to drop ``yes on 22'' literature off with
their orders.

In the context of the height of the COVID-19 pandemic, wherein these
workers are on the front lines, the prospect of being forced to
include leaflets containing specious arguments about what is best for
you in your relationship to the exploitation of your labor is
particularly grim.

\subsection{Marxist perspectives}
Along with the advance of technology comes a rich literature
investigating specific uses of technology and societal implications
resulting from those uses. \cite{burrell2021SocietyAlgorithms}
presents a thorough reading and framing of these topics that is
explicitly Marxist in perspective. They propose an extension of the
class divide formulated by Marx: The \emph{coding elite}, the upper
crust of programmers and tech executives, who organize society extract
wealth from the \emph{cybertariat}, who comprise a wide swath of
digital laborers.

Something that is underexplored here is the processes through which
the coding elite and cybertariat are produced. Central to the
formulation of this `Marxism with Silicon Valley characteristics' is
the notion of the `almighty code' - if one can touch, edit, or read
the codes or algorithms that drive Big Data innovations, one
inherently has more potential to advance through class structures than
those who do not touch code. This is mostly correct, but increasingly,
the cybertariat class can and does touch code, and yet are relegated
to cybertarian jobs. Computer science know-how does not necessarily
elevate a person on their own merits. Inter and intra-industry social
capital still plays an outsized role in determining if someone will
advance in class status - but this is a potential avenue for further
research. \footnote{As well, to consider a development of the utmost
recency, the various innovations being made in regards to Artificial
Intelligence imply an imminent disruption of the knowledge economy and
the way humans interact akin to the impact of the Google search
engine. This is sure to result in a wider distribution of coding
skills. \url{https://youtu.be/40Kp_fa8vIw?t=113}}

Here we must recognize that the relationship between the two classes
are significantly more obfuscated than they were in Marx's
time. Indeed, when considering the various End User License Agreements
and general opaqueness with which existing regulations are presented
to the consumer (and in the case of the gig worker, the presentation
of a labor contract), we are often agreeing to various breaches of
privacy through an increasingly sophisticated array of sensors,
algorithms, and third-party arrangements without knowing it
\citep{thatcher2016DataColonialism}. Meanwhile, the products are
commodified in privacy information markets.
\cite{thatcher2016DataColonialism} present these processes as
`data colonialism,' to counter the early framing of technologies as
`digital frontierism', arguing that the current relationships amount
to an ``accumulation by dispossession'', as formulated
by \cite{harvey2003NewImperialism}.

\subsection{Privacy Information Markets and Conclusion}
A privacy information market ``arises when privacy becomes a market
commodity that can be bought and sold'' \citep{crampton2015CollectIt}.
Individual data points, once abstracted and aggregated, are
algorithmically processed and used to generalize and predict
purchasing and consumption patterns. The Snowden documents revealed
that such patterns are being collected and acted upon at the national
and international levels in ways that are consequential to our
expectations of privacy. What is sure, but less clear, is that these
practices are widespread across private firms as well.

In 1961 Raymond Williams published a book containing an essay
titled \emph{Advertising: The Magic System}. Referring to advertising
as the official art of capitalism, he writes: \newline


\say{\emph{It is what `we' put up in `our' streets and use to fill up `our'
newspapers and magazines: and it commands the services of perhaps the
largest organized body of writers and artists, with their attendant
managers and advisers, in the whole
society.} \cite{williams1961AdvertisingMagic}}
\newline

Increasingly, the logics of advertising are informed
algorithmically. As human interaction moved online, tech firms were
able to claim the entirety of ownership of the new means of production
by framing uninhibited data harvesting as benign, even mutually
beneficial \citep{burrell2021SocietyAlgorithms}. In the intervening
years, with the advent of privacy information markets, the art of
capitalism is no longer just the work of the marketer, but it is also
passively performed by the marketed by virtue of data colonialism. As
well, the marketer is no longer limited to advertisement of goods and
services, but can monetize the processing of the aggregated data itself; as
described by \cite{crampton2015CollectIt}
\emph{vis-a-vis} Snowden, these practices permeate back and forth from the
private sector to the intelligence community and beyond, informing how
humans interact, associate, and
think \citep{burrell2021SocietyAlgorithms}. The `art' has already
conquered \emph{cspace} and \emph{cyberspace} \citep{batty1997VirtualGeography}, but
through the widespread application of computational logics to societal
organization, its tendrils are extending into \emph{cyberplace}.

